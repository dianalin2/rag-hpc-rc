{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977bd4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channel: https://www.youtube.com/playlist?list=PLT4bryHgBcRP7N-hB9u6EWs6tq_2nMoRO\n",
      "Found 2 videos in channel: RC Tutorial Series\n",
      "Loading video: Connecting to HPC (https://www.youtube.com/watch?v=94qLtfdsXaM)\n",
      "Loading video: Open OnDemand Interactive Apps (https://www.youtube.com/watch?v=o9XVUhCQuEI)\n"
     ]
    }
   ],
   "source": [
    "from langchain_yt_dlp import YoutubeLoaderDL\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "# Load the video metadata and transcript\n",
    "def load_youtube_video(url):\n",
    "    metadata_loader = YoutubeLoaderDL.from_youtube_url(\n",
    "        url,\n",
    "        add_video_info=True,\n",
    "    )\n",
    "\n",
    "    transcript_loader = YoutubeLoader.from_youtube_url(\n",
    "        url,\n",
    "        add_video_info=False,\n",
    "        transcript_format=TranscriptFormat.CHUNKS\n",
    "    )\n",
    "\n",
    "    metadata_docs = metadata_loader.load()\n",
    "    transcript_docs = transcript_loader.load()\n",
    "\n",
    "    for i, doc in enumerate(transcript_docs):\n",
    "        doc.metadata.update(metadata_docs[0].metadata)\n",
    "        doc.metadata['source_type'] = 'youtube'\n",
    "        doc.metadata['chunk_number'] = i + 1\n",
    "    \n",
    "    return transcript_docs\n",
    "\n",
    "# Load all videos from a YouTube channel\n",
    "def load_youtube_channel(channel_url):\n",
    "    ydl_opts = {\n",
    "        'extract_flat': True,\n",
    "        'quiet': True,\n",
    "        'force_generic_extractor': True,\n",
    "    }\n",
    "\n",
    "    print(f\"Loading channel: {channel_url}\")\n",
    "\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(channel_url, download=False)\n",
    "    \n",
    "    print(f\"Found {len(info.get('entries', []))} videos in channel: {info.get('title', 'Unknown Channel')}\")\n",
    "    \n",
    "    if 'entries' not in info:\n",
    "        raise ValueError(\"No entries found in the channel URL.\")\n",
    "    \n",
    "    documents = []\n",
    "    for entry in info['entries']:\n",
    "        video_url = entry['url']\n",
    "        print(f\"Loading video: {entry['title']} ({video_url})\")\n",
    "        docs = load_youtube_video(video_url)\n",
    "        documents.extend(docs)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# documents = load_youtube_channel('https://www.youtube.com/@UVAResearchComputing')\n",
    "documents = load_youtube_channel('https://www.youtube.com/playlist?list=PLT4bryHgBcRP7N-hB9u6EWs6tq_2nMoRO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8bb911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique video metadata entries: 2\n",
      "{'author': 'UVA Research Computing', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\", 'length': 411, 'publish_date': '2025-05-21', 'source': '94qLtfdsXaM', 'source_type': 'youtube', 'title': 'Connecting to HPC', 'view_count': 23, 'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM'}\n",
      "{'author': 'UVA Research Computing', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'length': 658, 'publish_date': '2025-06-15', 'source': 'o9XVUhCQuEI', 'source_type': 'youtube', 'title': 'Open OnDemand Interactive Apps', 'view_count': 15, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI'}\n"
     ]
    }
   ],
   "source": [
    "# print unique video metadatas\n",
    "import json\n",
    "\n",
    "unique_metadata = {json.dumps({k: v for k, v in d.metadata.items() if k not in ['chunk_number', 'start_seconds', 'start_timestamp']}, sort_keys=True) for d in documents}\n",
    "\n",
    "print(f\"Total unique video metadata entries: {len(unique_metadata)}\")\n",
    "\n",
    "for metadata in unique_metadata:\n",
    "    print(json.loads(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "CHROMA_PATH = \"./chroma\"\n",
    "COLLECTION_NAME = \"data\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen3\"\n",
    ")\n",
    "\n",
    "persistent_client = PersistentClient(\n",
    "    path=CHROMA_PATH,\n",
    ")\n",
    "\n",
    "collection = persistent_client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "def add_documents_to_vector_store(documents):\n",
    "    vector_store.add_documents(\n",
    "        documents=documents,\n",
    "        ids=[doc.metadata['source_type'] + \"_\" + doc.metadata['source'] + \"_\" + str(doc.metadata['chunk_number']) for doc in documents],\n",
    "    )\n",
    "    print(f\"Added {len(documents)} documents to the vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db2487a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 documents to the vector store.\n"
     ]
    }
   ],
   "source": [
    "add_documents_to_vector_store(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbecdca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in vector store: 7\n",
      "{'ids': ['youtube_94qLtfdsXaM_1', 'youtube_94qLtfdsXaM_2', 'youtube_94qLtfdsXaM_3', 'youtube_94qLtfdsXaM_4', 'youtube_o9XVUhCQuEI_1', 'youtube_o9XVUhCQuEI_2', 'youtube_o9XVUhCQuEI_3', 'youtube_o9XVUhCQuEI_4', 'youtube_o9XVUhCQuEI_5', 'youtube_o9XVUhCQuEI_6'], 'embeddings': None, 'documents': [\"Hello and welcome back to the University of Virginia's high performance computing tutorial series. In this module, we will cover three different ways to connect to the HPC system at UVA. The first method is open on demand, which is a web application accessed through a web browser. From there, you can manipulate files, work with jobs, and use a host of different guey applications. The second method is Fastex, which is another web application that gives you direct access to a Linux desktop where you can access your files, run guey applications, and use a browser within the HPC system. Lastly, there is SSH, the secure shell client, which gives you a command lineon view of the cluster. Let's start by going over open on demand. To connect, open your web browser and type .hpc.vergirginia.edu. Once you do that, you'll need to authenticate with your NetBatch computing ID and password. You could do this using any network, so you don't need to be using UVA Wi-Fi or the UVAVPN, making it very accessible. Open on Demand is a web application. If the browser ever freezes or you are waiting for certain changes to apply, you might have to refresh the pages. You could do this by either clicking the UVA open on demand button, which will navigate you back to the dashboard, or by refreshing your browser, which will likely unfreeze any browser issues or apply changes. Open on demand will also open many other tabs, such as text files or other applications. Generally, if you're not using those tabs, it's safe to close them. However, if you are writing a text file in one of those tabs, there is no automatic saving. So, you should periodically click save and then it will be safe to close that tab. This is what the dashboard looks like. The top bar contains all the actual functions of Open on Demand. First, we have the files tab. This is where you can manage and manipulate your files. Next is the jobs tab. Here you can create, run, and view your active jobs. The clusters dropdown allows you to open a command line. Under interactive apps, you can find all the interactive applications. Finally, we\", \"have the utility section. These are smaller applications designed to provide a graphical user interface for various tasks. Logging out of Open on Demand is simple. Just close your browser. Connecting with Fastex is another web-based login method which connects you directly to a desktop view. You can access it either through the open ondemand interactive apps menu or by using a direct link to Fastex Fastex.hpc.vergirginia.edu. Fastex requires you to be on the UVA network either by using on grounds Wi-Fi or Ethernet or by turning on the UVAVPN. If you are not on the UVA network, the page won't load. Once connected, it will prompt you to enter a username and password. Across all of research computing systems, if there is a username and password field, it's usually asking for your UVA computing ID and net batch password. Go ahead and log in. You will then be presented with a new screen where all of the applications that you can use are on the left. You can open up a terminal here to do command line work. The actual desktop login method is the Mate desktop. Click that and then click on the play button. It'll open up a new tab asking you how you want to connect. The browser client is recommended as the desktop client needs to be installed to your computer before use. Once you click on that, you'll be presented with the desktop on the cluster. From here, you can manipulate files either by clicking the folder icon to see all your files in your home folder or by clicking the filing cabinet icon on the top bar, which opens up the same screen. There are a couple of other dropowns. applications where you can open up different applications and system where you can log out. You can open up a terminal by clicking the terminal icon at the top. One of the most useful features of Fastax is the Firefox browser. Clicking on that will open up Firefox and you could browse the internet while on the cluster. Some use cases for this include accessing data on cloud storage platforms like Google Drive, UVA Box or Microsoft One Drive. If there is software you need to download, you can do it directly on the cluster through this browser. saving steps. If you are more familiar with\", \"guey applications or a guey text editor, you can open different guey applications from the terminal like G Vim. To log out, either go up to system and click log out or exit out of the browser. If you exit out of the browser, your session still exists. You should always terminate them when they're done. To terminate the session, click the little X at the top right, then terminate. You could always click the play button again to reopen your session. The last method of accessing HPC is connecting through the terminal using SSH. You would use this command SSH- capital Y your computing ID at login.hpc.vergirginia.edu. The -y option enables x11 forwarding which allows you to use guey applications through the command line on supported systems. However, it's slower than using fastex which we recommend for guey applications. If you're on Mac or Linux, you should already have an SSH interpreter built into your command line. Simply open a terminal and use that command. On newer versions of Windows, you can run the SSH command from PowerShell. If you have an older version of Windows, you might need to use a separate application. We recommend Mobile Exterm. Similar to Fastex, you must be on the UVA network to use SSH, either by being on grounds or using the UVAVPN. For this example, I'll be using Moba Xterm. The command I'll run is ssh mycomputing ID at login.hpc.vergirginia.edu. When you first use this command in mobile xterm, you'll be prompted to enter a password which is just your netbatch password. You'll know you've logged in because you'll see welcome to UVA HPC. Then you'll see the bash interpreter signified by the prompt on the left of the command line. From here you can go ahead and list your folders and do various tasks on the HPC system. To log out, you can use the command exit or if you simply close out of mobile exterm, it will cancel any SSH processes that are running, which will terminate your connection. One final note, some of the methods discussed in this video require using the UVAVPN if you are connecting\", \"from offgrounds. For details on installing and using the UVAVPN, see this link. Finally, if you need help with UVA's HPC system, there are multiple ways to get assistance. You can visit our Zoom based office hour sessions on Tuesdays from 3:00 to 5:00 p p.m. and Thursdays from 10:00 a.m. to noon. If you can't make it to these office hours or have a more specific request, you can submit a support ticket and we'll get back to you. Links to both are on the RC Learning website. The main research computing website is also a valuable resource. We add a lot of documentation here and keep it updated. If you have a basic question or think it might be covered already, we have an FAQ section. We also have a list of how-tos on various topics. If you can't find what you're looking for, we have a search feature where you can search our site for different information. This concludes the connecting to HBC tutorial at the University of Virginia. Thank you.\", \"Hello and welcome back to\\xa0\\nthe University of Virginia's\\xa0 High Performance Computing tutorial series. In this module, we will be covering the various\\xa0\\xa0 interactive apps that you can\\xa0\\naccess through Open OnDemand. These are all GUI apps like JupyterLab and\\xa0\\nRStudio Server that you can run directly on a\\xa0\\xa0 compute node rather than a login node, allowing\\xa0\\nyou to do computational work interactively. The login nodes are more for\\xa0\\nsetup or pre-production work,\\xa0\\xa0 whereas the interactive use of the\\xa0\\ncompute nodes is for compute jobs. That's where these interactive apps fit in. First, it's important to point out how\\xa0\\nthe resources on the cluster are managed. Getting access to the compute\\xa0\\nnodes is not as simple as just\\xa0\\xa0 logging into a login node\\xa0\\nand starting to run work. You have to go through our\\xa0\\nresource manager, called Slurm. You can think of it as a queuing system. When you submit a job, you'll\\xa0\\nspecify the resources you need,\\xa0\\xa0 such as the number of nodes,\\xa0\\ncore count, memory, and time. All of that gets bundled into a\\xa0\\nrequest that is then sent to Slurm. A process within Slurm called the scheduler looks\\xa0\\xa0 at all the resources you've requested and\\xa0\\nassigns your job some amount of priority. The priority determines where your\\xa0\\njob will sit within the queue. If the resources you need are\\xa0\\nimmediately available and there\\xa0\\xa0 aren't many other jobs waiting,\\xa0\\nyour job might submit immediately. However, if you're requesting\\xa0\\na larger amount of resources\\xa0\\xa0 or the queue is very busy at that\\xa0\\ntime, your job might have to wait. Slurm will use the job's\\xa0\\npriority to place it in a queue,\\xa0\\xa0 starting your job once it's next in\\xa0\\nline and the resources are ready. When you submit a job, you're submitting\\xa0\\nit to one of Slurm's different partitions. Partitions are different chunks of\\xa0\\ncompute nodes with various limitations,\\xa0\\xa0 each meant for different kinds of jobs. For example, there is the standard partition\\xa0\\nwhere you're only allowed to run single node jobs,\\xa0\\xa0 the parallel partition where\\xa0\\nyou can request up to 64 nodes,\\xa0\\xa0 the GPU partition for GPU jobs, and other\\xa0\\ndedicated partitions with specific purposes. A full list of all the different queues and\\xa0\\nresources is also available on our website. To use the interactive apps, you'll\\xa0\\nuse the Interactive Apps menu dropdown. This drop-down lists all\\xa0\\nthe different apps we offer.\", \"The main ones this video\\xa0\\nwill focus on are JupyterLab,\\xa0\\xa0 RStudio Server, the desktop app, and Matlab. But all the other apps have\\xa0\\nsimilar setup processes. I'll start by requesting a JupyterLab session. When I click on JupyterLab, it takes me to\\xa0\\na different page with a form to fill out,\\xa0\\xa0 where I can specify the resources I\\xa0\\nwant to request for my interactive job. The first thing you'll be asked is\\xa0\\nwhich partition you want to run on. You can select between interactive, standard, GPU,\\xa0\\nor any other partitions you may have access to. After that, you will specify the amount\\xa0\\nof time you want for your session. You can use the slider or\\xa0\\ninput the number you need. Keep in mind that this time limit is a hard limit. For example, if you set the session\\xa0\\nfor an hour, once the hour has passed,\\xa0\\xa0 Slurm will cut any ongoing processes and\\xa0\\nyou'll be disconnected from the session. You'll have to start a new one to\\xa0\\ncontinue working on a compute node. This time limit comes without any warnings,\\xa0\\nso make sure you're requesting enough time\\xa0\\xa0 and maybe add an extra hour if\\xa0\\nyou think you might need it. Next, there's the number of cores,\\xa0\\xa0 which is only relevant if you're running code\\xa0\\nthat can take advantage of multiple cores. For example, if your code is multi-threaded,\\xa0\\nyou'll want to request more cores. If you're unsure or if your code doesn't\\xa0\\nrequire multiple cores, stick with one core. Then there's the memory request. This is where you'll request\\xa0\\nmore RAM if your job needs it. It can be difficult to determine\\xa0\\nhow much memory you need beforehand. A general rule of thumb is to request about two to\\xa0\\xa0 three times the amount of RAM as the amount\\xa0\\nof data you're working with in gigabytes. For example, if you're working\\xa0\\nwith a 10 gigabyte data file,\\xa0\\xa0 you might want to request between\\xa0\\n20 and 30 gigabytes of memory. This is just for loading the data. Processing the data might require more. It can be a bit of a guessing game. Next is the working directory. For JupyterLab, this will be the folder\\xa0\\nfrom which you can open notebooks. I'll select home here. Then there's the dropdown for your allocation. It should be auto-filled with one already,\\xa0\\nbut you can click on it and select between\\xa0\\xa0 the different allocations you're a\\xa0\\npart of if you're a member of multiple. This allocation is where the service\\xa0\\nunits you're using get billed to. In the interactive partition, there are\\xa0\\na couple of nodes that have GPUs in them.\", \"You can request these using the optional\\xa0\\ndropdown, and you can request up to two GPUs. When switching to the GPU partition,\\xa0\\nthis option is replaced with GPU type. If you select the default option,\\xa0\\xa0 it will give you whichever GPU is\\xa0\\nnext available without any preference. If you click the dropdown, you can request a\\xa0\\nspecific GPU like the A100, V100, A40, etc. You can request up to four\\xa0\\nGPUs using the number input. Under Show Additional Options, if you select Yes,\\xa0\\xa0 there is a field where you can\\xa0\\nadd any other Slurm options. There are many different\\xa0\\nSlurm options you can use. I recommend looking at Slurm's documentation\\xa0\\nor the Slurm page on our website. For example, if you have a reservation\\xa0\\nfor a class, you can use --reservation=\\xa0 followed by whatever your professor gives you. If you want to exclude certain\\xa0\\nnodes from your job search,\\xa0\\xa0 you can use the exclude option and specify\\xa0\\nthe nodes you don't want your job to run on. These are just a couple of examples. If you're a member of over 16 groups,\\xa0\\nthere are some permission issues that\\xa0\\xa0 can pop up because the system\\xa0\\nonly allows access to 16 groups. If you need access to a storage\\xa0\\nshare or certain software,\\xa0\\xa0 and you are in more than 16 groups,\\xa0\\nyou might need to specify a group here. The last checkbox allows you to receive\\xa0\\nan email when your session starts. If you're waiting a long time and want\\xa0\\nto know when you can start working,\\xa0\\xa0 this could be a good option to select. This form saves your preferences\\xa0\\nfor future use so that you don't\\xa0\\xa0 have to fill out everything on\\xa0\\nthe form again in the future. Once you're done filling out the form, click\\xa0\\nthe Launch button to submit your job to Slurm. It will then take you to the\\xa0\\nMy Interactive Sessions page. As you can see, my job is queued up. I have requested an hour and there are\\xa0\\nsome session details here if I click on it. The resources I've requested, one hour\\xa0\\non one core, is a very small request. Generally, you should expect a\\xa0\\njob like that to start almost\\xa0\\xa0 immediately because there is usually one\\xa0\\ncore available somewhere on the system,\\xa0\\xa0 especially in the interactive\\xa0\\nor standard partition. If, however, I'd requested a full node, like\\xa0\\n40 to the 96 cores available on the node,\\xa0\\xa0 for the maximum amount of time on that\\xa0\\npartition, that job will probably be queued\\xa0\\xa0\", \"for a longer period of time, because\\xa0\\nthe resources might not be available. Additionally, a bigger job will have less\\xa0\\npriority than a smaller request like this one. Generally, smaller requests\\xa0\\nequal faster submission,\\xa0\\xa0 while larger requests mean a longer wait time. Once your job starts, you'll see the\\xa0\\nstatus change from Queued to Running. Once the resources are ready, the time\\xa0\\nrequested switches to time remaining. To actually connect to the session, I'll click\\xa0\\nConnect to Jupyter, which will open another tab. As you can see, I've got JupyterLab open,\\xa0\\xa0 where I can run notebooks and code on the\\xa0\\ncompute nodes, rather than the login nodes. There are a couple of different tiles here, like\\xa0\\na base Python 3 tile for running Python 3.11 code. There are pre-built tiles for popular\\xa0\\npackages like PyTorch and TensorFlow,\\xa0\\xa0 a Rapids tile, and an R tile. You also have the ability to create custom tiles. If you scroll further down, you can\\xa0\\nopen a terminal using this button. This is useful if you need to pip\\xa0\\ninstall or conda install any packages. On the left is the file system,\\xa0\\nspecifically my home directory. You can't navigate further back to open\\xa0\\nfiles from scratch or project directly,\\xa0\\xa0 but the session does have\\xa0\\naccess to the full file system. So my code can still read or\\xa0\\nmodify data in my scratch folder. I just can't open a Jupyter\\xa0\\nnotebook for my scratch folder. The session is tied to my browser window. If I exit out of it, I can always reconnect by\\xa0\\nclicking Connect, which will reopen the session. However, JupyterLab is sensitive to the\\xa0\\nbrowser and the local internet connection. If I have code running and exit\\xa0\\nthe browser, the code will stop. Similarly, if my Wi-Fi cuts\\xa0\\nout, the code will also stop. This limitation is specific to JupyterLab\\xa0\\nand doesn't affect other interactive apps. Once I'm done with my session,\\xa0\\nI can close the browser and end\\xa0\\xa0 my session by clicking the big red Delete button. It's best practice to end any sessions early when\\xa0\\nyou're done, instead of letting them sit idle. We only charge SUs based on time\\xa0\\nused, not the time requested. So if I end the session early,\\xa0\\xa0 I'll only be charged for time used,\\xa0\\nwhich can matter for your allocation. Additionally, if I don't delete my session,\\xa0\\nthe resources will sit idle, which isn't ideal.\", \"We want unused resources\\xa0\\nto be available for others. To delete the session, I'll\\xa0\\nclick Delete, confirm the action,\\xa0\\xa0 and then my session will be successfully deleted. Another app available on Open OnDemand is RStudio. Starting an RStudio session is similar to\\xa0\\nJupyterLab, but the form is slightly different. You'll be prompted to select an R version. In addition, there is no\\xa0\\noption for work directory,\\xa0\\xa0 since you can navigate to the\\xa0\\nwhole file system from RStudio. All other options in the form are the same. This is what RStudio itself looks like. You've got the console on the left\\xa0\\nand your file system on the right. RStudio can continue any active processes even\\xa0\\xa0 if your connection drops or\\xa0\\nyou close out of the browser. If you exit out and want to continue the\\xa0\\nsession or check if the code is still running,\\xa0\\xa0 you can always relaunch the session\\xa0\\nusing the button that will pop up. Starting up the other interactive apps is similar. So here's a quick overview of some\\xa0\\nof them and what they're useful for. One of the most useful apps is\\xa0\\nthe Desktop interactive app. This will open a desktop that\\xa0\\nis identical to the FastX one,\\xa0\\xa0 but instead of being on a login\\xa0\\nnode it will run on a compute node. This can be useful for users who\\xa0\\nwant to use GUI-based software. You can use the desktop app to run computationally\\xa0\\xa0 intensive work on a compute node rather\\xa0\\nthan using FastX on the login node. Additionally, if you have a large\\xa0\\namount of data to download from\\xa0\\xa0 cloud services like Google Drive,\\xa0\\nUVA Box, or Microsoft OneDrive,\\xa0\\xa0 you might find better performance on a\\xa0\\ncompute node rather than a login node. You can start these downloads and\\xa0\\nthen leave your computer for a bit. The downloads will continue even if you\\xa0\\nclose the browser or turn off your computer. The desktop app has this functionality because it\\xa0\\xa0 doesn't rely on your local internet\\xa0\\nconnection or the browser being open. This is a great way to run something on the\\xa0\\xa0 cluster in the background\\xa0\\nand come back to it later. Another available app is Matlab. Similar to RStudio, you will request what version\\xa0\\xa0 of Matlab you want to use\\xa0\\nwhen launching the session. Launching it will open the Matlab\\xa0\\ndesktop app within a desktop environment,\\xa0\\xa0 but closing the Matlab app will exit the session. If your files are not visible on the\\xa0\\ndesktop, you can access them from\\xa0\\xa0\", \"the Places menu or the Caja app, which is the\\xa0\\nfiling cabinet icon at the top of the screen. Both Matlab and the desktop app persist if your\\xa0\\nnetwork is disconnected or if your browser closes. You can always relaunch those sessions to\\xa0\\nreconnect and your code will still be running. Finally, if you need help with UVA's HPC system,\\xa0\\nthere are multiple ways to get assistance. You can visit our Zoom-based office hours sessions\\xa0\\xa0 on Tuesdays from 3-5pm and\\xa0\\nThursdays from 10am to noon. If you can't make it to these office\\xa0\\nhours or have a more specific request,\\xa0\\xa0 you can submit a support ticket\\xa0\\nand we'll get back to you. Links to both are on the RC Learning website. The main Research Computing website\\xa0\\nis also a valuable resource. We add a lot of documentation\\xa0\\nhere and keep it updated. If you have a basic question or think it might\\xa0\\nbe covered already, we have an FAQ section. We also have a list of how to's on various topics. If you can't find what you're looking for,\\xa0\\xa0 we have a search feature where you can\\xa0\\nsearch our site for different information. This concludes the Open OnDemand Interactive\\xa0\\nApps tutorial at the University of Virginia. Thank you.\"], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source_type': 'youtube', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\", 'start_timestamp': '00:00:00', 'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM', 'start_seconds': 0, 'length': 411, 'chunk_number': 1, 'title': 'Connecting to HPC', 'author': 'UVA Research Computing', 'transcript_chunk_number': 1, 'publish_date': '2025-05-21', 'view_count': 23, 'source': '94qLtfdsXaM'}, {'source': '94qLtfdsXaM', 'transcript_chunk_number': 2, 'start_timestamp': '00:02:00', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'view_count': 23, 'title': 'Connecting to HPC', 'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM', 'publish_date': '2025-05-21', 'start_seconds': 120, 'length': 411, 'author': 'UVA Research Computing', 'source_type': 'youtube', 'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\", 'chunk_number': 2}, {'title': 'Connecting to HPC', 'author': 'UVA Research Computing', 'start_timestamp': '00:04:00', 'view_count': 23, 'start_seconds': 240, 'publish_date': '2025-05-21', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'source': '94qLtfdsXaM', 'length': 411, 'transcript_chunk_number': 3, 'source_type': 'youtube', 'chunk_number': 3, 'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\", 'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM'}, {'transcript_chunk_number': 4, 'title': 'Connecting to HPC', 'source_type': 'youtube', 'start_timestamp': '00:06:00', 'chunk_number': 4, 'source': '94qLtfdsXaM', 'start_seconds': 360, 'length': 411, 'author': 'UVA Research Computing', 'view_count': 23, 'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\", 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'publish_date': '2025-05-21', 'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM'}, {'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'chunk_number': 1, 'source_type': 'youtube', 'source': 'o9XVUhCQuEI', 'transcript_chunk_number': 1, 'publish_date': '2025-06-15', 'author': 'UVA Research Computing', 'length': 658, 'start_timestamp': '00:00:00', 'view_count': 15, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'title': 'Open OnDemand Interactive Apps', 'start_seconds': 0}, {'source_type': 'youtube', 'title': 'Open OnDemand Interactive Apps', 'author': 'UVA Research Computing', 'chunk_number': 2, 'source': 'o9XVUhCQuEI', 'transcript_chunk_number': 2, 'view_count': 15, 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'length': 658, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'start_seconds': 120, 'publish_date': '2025-06-15', 'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'start_timestamp': '00:02:00'}, {'start_timestamp': '00:04:00', 'start_seconds': 240, 'source': 'o9XVUhCQuEI', 'length': 658, 'transcript_chunk_number': 3, 'chunk_number': 3, 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'publish_date': '2025-06-15', 'view_count': 15, 'author': 'UVA Research Computing', 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'title': 'Open OnDemand Interactive Apps', 'source_type': 'youtube', 'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help'}, {'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'author': 'UVA Research Computing', 'transcript_chunk_number': 4, 'source': 'o9XVUhCQuEI', 'publish_date': '2025-06-15', 'title': 'Open OnDemand Interactive Apps', 'chunk_number': 4, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'start_seconds': 360, 'source_type': 'youtube', 'start_timestamp': '00:06:00', 'view_count': 15, 'length': 658}, {'length': 658, 'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'chunk_number': 5, 'start_seconds': 480, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'transcript_chunk_number': 5, 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'author': 'UVA Research Computing', 'view_count': 15, 'source': 'o9XVUhCQuEI', 'source_type': 'youtube', 'publish_date': '2025-06-15', 'start_timestamp': '00:08:00', 'title': 'Open OnDemand Interactive Apps'}, {'publish_date': '2025-06-15', 'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help', 'chunk_number': 6, 'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI', 'author': 'UVA Research Computing', 'source_type': 'youtube', 'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag', 'length': 658, 'title': 'Open OnDemand Interactive Apps', 'start_timestamp': '00:10:00', 'source': 'o9XVUhCQuEI', 'start_seconds': 600, 'view_count': 15, 'transcript_chunk_number': 6}]}\n",
      "{\n",
      "  \"response\": \"Open OnDemand is a web-based portal that provides access to various interactive applications and tools available through the University of Virginia Research Computing (UVA RC). It allows users to launch applications like JupyterLab, RStudio Server, and others, as well as connect to desktop environments and manage computational resources.\",\n",
      "  \"sources\": [\n",
      "    \"Source: [Connecting to HPC](https://www.youtube.com/watch?v=94qLtfdsXaM) by [UVA Research Computing](https://www.youtube.com/channel/UCDjikQvnYrZ3aNIdKgU54ag)\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import json\n",
    "\n",
    "def rag_query(query):\n",
    "    \"\"\"\n",
    "    Perform a RAG query on the Chroma vector store.\n",
    "    \"\"\"\n",
    "    # print number of documents in the vector store\n",
    "    print(f\"Number of documents in vector store: {len(vector_store.get())}\")\n",
    "\n",
    "    docs = vector_store.similarity_search_with_relevance_scores(query, k=5)\n",
    "    context = \"\\n\".join([result.page_content for result, _ in docs]) if docs else \"No relevant documents found.\"\n",
    "    print(vector_store.get())\n",
    "    # print(f\"Context for query '{query}': {context}\")\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a chatbot for University of Virginia Research Computing (UVA RC). You are given the following context from the UVA RC YouTube channel and from various other UVA RC resources. Respond to the question using the context provided succinctly and accurately.\n",
    "    Context: {context}\n",
    "    Question: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    chat = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen3\",\n",
    "    )\n",
    "\n",
    "    # disable thinking \n",
    "    response = chat.invoke(prompt, think=False)\n",
    "\n",
    "    sources = {doc.metadata[\"source_type\"]: doc.metadata for doc, _score in docs}\n",
    "\n",
    "    sources_formatted = []\n",
    "    for source_type, metadata in sources.items():\n",
    "        if source_type == \"youtube\":\n",
    "            sources_formatted.append(f'Source: [{metadata[\"title\"]}]({metadata[\"webpage_url\"]}) by [{metadata[\"author\"]}](https://www.youtube.com/channel/{metadata[\"channel_id\"]})')\n",
    "\n",
    "    formatted_response = json.dumps({\n",
    "        \"response\": response.content,\n",
    "        \"sources\": sources_formatted\n",
    "    }, indent=2)\n",
    "\n",
    "    print(formatted_response)\n",
    "\n",
    "# Example query\n",
    "rag_query(\"What is Open OnDemand?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf86a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['youtube_94qLtfdsXaM_1',\n",
       "  'youtube_94qLtfdsXaM_2',\n",
       "  'youtube_94qLtfdsXaM_3',\n",
       "  'youtube_94qLtfdsXaM_4',\n",
       "  'youtube_o9XVUhCQuEI_1',\n",
       "  'youtube_o9XVUhCQuEI_2',\n",
       "  'youtube_o9XVUhCQuEI_3',\n",
       "  'youtube_o9XVUhCQuEI_4',\n",
       "  'youtube_o9XVUhCQuEI_5',\n",
       "  'youtube_o9XVUhCQuEI_6'],\n",
       " 'embeddings': None,\n",
       " 'documents': [\"Hello and welcome back to the University of Virginia's high performance computing tutorial series. In this module, we will cover three different ways to connect to the HPC system at UVA. The first method is open on demand, which is a web application accessed through a web browser. From there, you can manipulate files, work with jobs, and use a host of different guey applications. The second method is Fastex, which is another web application that gives you direct access to a Linux desktop where you can access your files, run guey applications, and use a browser within the HPC system. Lastly, there is SSH, the secure shell client, which gives you a command lineon view of the cluster. Let's start by going over open on demand. To connect, open your web browser and type .hpc.vergirginia.edu. Once you do that, you'll need to authenticate with your NetBatch computing ID and password. You could do this using any network, so you don't need to be using UVA Wi-Fi or the UVAVPN, making it very accessible. Open on Demand is a web application. If the browser ever freezes or you are waiting for certain changes to apply, you might have to refresh the pages. You could do this by either clicking the UVA open on demand button, which will navigate you back to the dashboard, or by refreshing your browser, which will likely unfreeze any browser issues or apply changes. Open on demand will also open many other tabs, such as text files or other applications. Generally, if you're not using those tabs, it's safe to close them. However, if you are writing a text file in one of those tabs, there is no automatic saving. So, you should periodically click save and then it will be safe to close that tab. This is what the dashboard looks like. The top bar contains all the actual functions of Open on Demand. First, we have the files tab. This is where you can manage and manipulate your files. Next is the jobs tab. Here you can create, run, and view your active jobs. The clusters dropdown allows you to open a command line. Under interactive apps, you can find all the interactive applications. Finally, we\",\n",
       "  \"have the utility section. These are smaller applications designed to provide a graphical user interface for various tasks. Logging out of Open on Demand is simple. Just close your browser. Connecting with Fastex is another web-based login method which connects you directly to a desktop view. You can access it either through the open ondemand interactive apps menu or by using a direct link to Fastex Fastex.hpc.vergirginia.edu. Fastex requires you to be on the UVA network either by using on grounds Wi-Fi or Ethernet or by turning on the UVAVPN. If you are not on the UVA network, the page won't load. Once connected, it will prompt you to enter a username and password. Across all of research computing systems, if there is a username and password field, it's usually asking for your UVA computing ID and net batch password. Go ahead and log in. You will then be presented with a new screen where all of the applications that you can use are on the left. You can open up a terminal here to do command line work. The actual desktop login method is the Mate desktop. Click that and then click on the play button. It'll open up a new tab asking you how you want to connect. The browser client is recommended as the desktop client needs to be installed to your computer before use. Once you click on that, you'll be presented with the desktop on the cluster. From here, you can manipulate files either by clicking the folder icon to see all your files in your home folder or by clicking the filing cabinet icon on the top bar, which opens up the same screen. There are a couple of other dropowns. applications where you can open up different applications and system where you can log out. You can open up a terminal by clicking the terminal icon at the top. One of the most useful features of Fastax is the Firefox browser. Clicking on that will open up Firefox and you could browse the internet while on the cluster. Some use cases for this include accessing data on cloud storage platforms like Google Drive, UVA Box or Microsoft One Drive. If there is software you need to download, you can do it directly on the cluster through this browser. saving steps. If you are more familiar with\",\n",
       "  \"guey applications or a guey text editor, you can open different guey applications from the terminal like G Vim. To log out, either go up to system and click log out or exit out of the browser. If you exit out of the browser, your session still exists. You should always terminate them when they're done. To terminate the session, click the little X at the top right, then terminate. You could always click the play button again to reopen your session. The last method of accessing HPC is connecting through the terminal using SSH. You would use this command SSH- capital Y your computing ID at login.hpc.vergirginia.edu. The -y option enables x11 forwarding which allows you to use guey applications through the command line on supported systems. However, it's slower than using fastex which we recommend for guey applications. If you're on Mac or Linux, you should already have an SSH interpreter built into your command line. Simply open a terminal and use that command. On newer versions of Windows, you can run the SSH command from PowerShell. If you have an older version of Windows, you might need to use a separate application. We recommend Mobile Exterm. Similar to Fastex, you must be on the UVA network to use SSH, either by being on grounds or using the UVAVPN. For this example, I'll be using Moba Xterm. The command I'll run is ssh mycomputing ID at login.hpc.vergirginia.edu. When you first use this command in mobile xterm, you'll be prompted to enter a password which is just your netbatch password. You'll know you've logged in because you'll see welcome to UVA HPC. Then you'll see the bash interpreter signified by the prompt on the left of the command line. From here you can go ahead and list your folders and do various tasks on the HPC system. To log out, you can use the command exit or if you simply close out of mobile exterm, it will cancel any SSH processes that are running, which will terminate your connection. One final note, some of the methods discussed in this video require using the UVAVPN if you are connecting\",\n",
       "  \"from offgrounds. For details on installing and using the UVAVPN, see this link. Finally, if you need help with UVA's HPC system, there are multiple ways to get assistance. You can visit our Zoom based office hour sessions on Tuesdays from 3:00 to 5:00 p p.m. and Thursdays from 10:00 a.m. to noon. If you can't make it to these office hours or have a more specific request, you can submit a support ticket and we'll get back to you. Links to both are on the RC Learning website. The main research computing website is also a valuable resource. We add a lot of documentation here and keep it updated. If you have a basic question or think it might be covered already, we have an FAQ section. We also have a list of how-tos on various topics. If you can't find what you're looking for, we have a search feature where you can search our site for different information. This concludes the connecting to HBC tutorial at the University of Virginia. Thank you.\",\n",
       "  \"Hello and welcome back to\\xa0\\nthe University of Virginia's\\xa0 High Performance Computing tutorial series. In this module, we will be covering the various\\xa0\\xa0 interactive apps that you can\\xa0\\naccess through Open OnDemand. These are all GUI apps like JupyterLab and\\xa0\\nRStudio Server that you can run directly on a\\xa0\\xa0 compute node rather than a login node, allowing\\xa0\\nyou to do computational work interactively. The login nodes are more for\\xa0\\nsetup or pre-production work,\\xa0\\xa0 whereas the interactive use of the\\xa0\\ncompute nodes is for compute jobs. That's where these interactive apps fit in. First, it's important to point out how\\xa0\\nthe resources on the cluster are managed. Getting access to the compute\\xa0\\nnodes is not as simple as just\\xa0\\xa0 logging into a login node\\xa0\\nand starting to run work. You have to go through our\\xa0\\nresource manager, called Slurm. You can think of it as a queuing system. When you submit a job, you'll\\xa0\\nspecify the resources you need,\\xa0\\xa0 such as the number of nodes,\\xa0\\ncore count, memory, and time. All of that gets bundled into a\\xa0\\nrequest that is then sent to Slurm. A process within Slurm called the scheduler looks\\xa0\\xa0 at all the resources you've requested and\\xa0\\nassigns your job some amount of priority. The priority determines where your\\xa0\\njob will sit within the queue. If the resources you need are\\xa0\\nimmediately available and there\\xa0\\xa0 aren't many other jobs waiting,\\xa0\\nyour job might submit immediately. However, if you're requesting\\xa0\\na larger amount of resources\\xa0\\xa0 or the queue is very busy at that\\xa0\\ntime, your job might have to wait. Slurm will use the job's\\xa0\\npriority to place it in a queue,\\xa0\\xa0 starting your job once it's next in\\xa0\\nline and the resources are ready. When you submit a job, you're submitting\\xa0\\nit to one of Slurm's different partitions. Partitions are different chunks of\\xa0\\ncompute nodes with various limitations,\\xa0\\xa0 each meant for different kinds of jobs. For example, there is the standard partition\\xa0\\nwhere you're only allowed to run single node jobs,\\xa0\\xa0 the parallel partition where\\xa0\\nyou can request up to 64 nodes,\\xa0\\xa0 the GPU partition for GPU jobs, and other\\xa0\\ndedicated partitions with specific purposes. A full list of all the different queues and\\xa0\\nresources is also available on our website. To use the interactive apps, you'll\\xa0\\nuse the Interactive Apps menu dropdown. This drop-down lists all\\xa0\\nthe different apps we offer.\",\n",
       "  \"The main ones this video\\xa0\\nwill focus on are JupyterLab,\\xa0\\xa0 RStudio Server, the desktop app, and Matlab. But all the other apps have\\xa0\\nsimilar setup processes. I'll start by requesting a JupyterLab session. When I click on JupyterLab, it takes me to\\xa0\\na different page with a form to fill out,\\xa0\\xa0 where I can specify the resources I\\xa0\\nwant to request for my interactive job. The first thing you'll be asked is\\xa0\\nwhich partition you want to run on. You can select between interactive, standard, GPU,\\xa0\\nor any other partitions you may have access to. After that, you will specify the amount\\xa0\\nof time you want for your session. You can use the slider or\\xa0\\ninput the number you need. Keep in mind that this time limit is a hard limit. For example, if you set the session\\xa0\\nfor an hour, once the hour has passed,\\xa0\\xa0 Slurm will cut any ongoing processes and\\xa0\\nyou'll be disconnected from the session. You'll have to start a new one to\\xa0\\ncontinue working on a compute node. This time limit comes without any warnings,\\xa0\\nso make sure you're requesting enough time\\xa0\\xa0 and maybe add an extra hour if\\xa0\\nyou think you might need it. Next, there's the number of cores,\\xa0\\xa0 which is only relevant if you're running code\\xa0\\nthat can take advantage of multiple cores. For example, if your code is multi-threaded,\\xa0\\nyou'll want to request more cores. If you're unsure or if your code doesn't\\xa0\\nrequire multiple cores, stick with one core. Then there's the memory request. This is where you'll request\\xa0\\nmore RAM if your job needs it. It can be difficult to determine\\xa0\\nhow much memory you need beforehand. A general rule of thumb is to request about two to\\xa0\\xa0 three times the amount of RAM as the amount\\xa0\\nof data you're working with in gigabytes. For example, if you're working\\xa0\\nwith a 10 gigabyte data file,\\xa0\\xa0 you might want to request between\\xa0\\n20 and 30 gigabytes of memory. This is just for loading the data. Processing the data might require more. It can be a bit of a guessing game. Next is the working directory. For JupyterLab, this will be the folder\\xa0\\nfrom which you can open notebooks. I'll select home here. Then there's the dropdown for your allocation. It should be auto-filled with one already,\\xa0\\nbut you can click on it and select between\\xa0\\xa0 the different allocations you're a\\xa0\\npart of if you're a member of multiple. This allocation is where the service\\xa0\\nunits you're using get billed to. In the interactive partition, there are\\xa0\\na couple of nodes that have GPUs in them.\",\n",
       "  \"You can request these using the optional\\xa0\\ndropdown, and you can request up to two GPUs. When switching to the GPU partition,\\xa0\\nthis option is replaced with GPU type. If you select the default option,\\xa0\\xa0 it will give you whichever GPU is\\xa0\\nnext available without any preference. If you click the dropdown, you can request a\\xa0\\nspecific GPU like the A100, V100, A40, etc. You can request up to four\\xa0\\nGPUs using the number input. Under Show Additional Options, if you select Yes,\\xa0\\xa0 there is a field where you can\\xa0\\nadd any other Slurm options. There are many different\\xa0\\nSlurm options you can use. I recommend looking at Slurm's documentation\\xa0\\nor the Slurm page on our website. For example, if you have a reservation\\xa0\\nfor a class, you can use --reservation=\\xa0 followed by whatever your professor gives you. If you want to exclude certain\\xa0\\nnodes from your job search,\\xa0\\xa0 you can use the exclude option and specify\\xa0\\nthe nodes you don't want your job to run on. These are just a couple of examples. If you're a member of over 16 groups,\\xa0\\nthere are some permission issues that\\xa0\\xa0 can pop up because the system\\xa0\\nonly allows access to 16 groups. If you need access to a storage\\xa0\\nshare or certain software,\\xa0\\xa0 and you are in more than 16 groups,\\xa0\\nyou might need to specify a group here. The last checkbox allows you to receive\\xa0\\nan email when your session starts. If you're waiting a long time and want\\xa0\\nto know when you can start working,\\xa0\\xa0 this could be a good option to select. This form saves your preferences\\xa0\\nfor future use so that you don't\\xa0\\xa0 have to fill out everything on\\xa0\\nthe form again in the future. Once you're done filling out the form, click\\xa0\\nthe Launch button to submit your job to Slurm. It will then take you to the\\xa0\\nMy Interactive Sessions page. As you can see, my job is queued up. I have requested an hour and there are\\xa0\\nsome session details here if I click on it. The resources I've requested, one hour\\xa0\\non one core, is a very small request. Generally, you should expect a\\xa0\\njob like that to start almost\\xa0\\xa0 immediately because there is usually one\\xa0\\ncore available somewhere on the system,\\xa0\\xa0 especially in the interactive\\xa0\\nor standard partition. If, however, I'd requested a full node, like\\xa0\\n40 to the 96 cores available on the node,\\xa0\\xa0 for the maximum amount of time on that\\xa0\\npartition, that job will probably be queued\\xa0\\xa0\",\n",
       "  \"for a longer period of time, because\\xa0\\nthe resources might not be available. Additionally, a bigger job will have less\\xa0\\npriority than a smaller request like this one. Generally, smaller requests\\xa0\\nequal faster submission,\\xa0\\xa0 while larger requests mean a longer wait time. Once your job starts, you'll see the\\xa0\\nstatus change from Queued to Running. Once the resources are ready, the time\\xa0\\nrequested switches to time remaining. To actually connect to the session, I'll click\\xa0\\nConnect to Jupyter, which will open another tab. As you can see, I've got JupyterLab open,\\xa0\\xa0 where I can run notebooks and code on the\\xa0\\ncompute nodes, rather than the login nodes. There are a couple of different tiles here, like\\xa0\\na base Python 3 tile for running Python 3.11 code. There are pre-built tiles for popular\\xa0\\npackages like PyTorch and TensorFlow,\\xa0\\xa0 a Rapids tile, and an R tile. You also have the ability to create custom tiles. If you scroll further down, you can\\xa0\\nopen a terminal using this button. This is useful if you need to pip\\xa0\\ninstall or conda install any packages. On the left is the file system,\\xa0\\nspecifically my home directory. You can't navigate further back to open\\xa0\\nfiles from scratch or project directly,\\xa0\\xa0 but the session does have\\xa0\\naccess to the full file system. So my code can still read or\\xa0\\nmodify data in my scratch folder. I just can't open a Jupyter\\xa0\\nnotebook for my scratch folder. The session is tied to my browser window. If I exit out of it, I can always reconnect by\\xa0\\nclicking Connect, which will reopen the session. However, JupyterLab is sensitive to the\\xa0\\nbrowser and the local internet connection. If I have code running and exit\\xa0\\nthe browser, the code will stop. Similarly, if my Wi-Fi cuts\\xa0\\nout, the code will also stop. This limitation is specific to JupyterLab\\xa0\\nand doesn't affect other interactive apps. Once I'm done with my session,\\xa0\\nI can close the browser and end\\xa0\\xa0 my session by clicking the big red Delete button. It's best practice to end any sessions early when\\xa0\\nyou're done, instead of letting them sit idle. We only charge SUs based on time\\xa0\\nused, not the time requested. So if I end the session early,\\xa0\\xa0 I'll only be charged for time used,\\xa0\\nwhich can matter for your allocation. Additionally, if I don't delete my session,\\xa0\\nthe resources will sit idle, which isn't ideal.\",\n",
       "  \"We want unused resources\\xa0\\nto be available for others. To delete the session, I'll\\xa0\\nclick Delete, confirm the action,\\xa0\\xa0 and then my session will be successfully deleted. Another app available on Open OnDemand is RStudio. Starting an RStudio session is similar to\\xa0\\nJupyterLab, but the form is slightly different. You'll be prompted to select an R version. In addition, there is no\\xa0\\noption for work directory,\\xa0\\xa0 since you can navigate to the\\xa0\\nwhole file system from RStudio. All other options in the form are the same. This is what RStudio itself looks like. You've got the console on the left\\xa0\\nand your file system on the right. RStudio can continue any active processes even\\xa0\\xa0 if your connection drops or\\xa0\\nyou close out of the browser. If you exit out and want to continue the\\xa0\\nsession or check if the code is still running,\\xa0\\xa0 you can always relaunch the session\\xa0\\nusing the button that will pop up. Starting up the other interactive apps is similar. So here's a quick overview of some\\xa0\\nof them and what they're useful for. One of the most useful apps is\\xa0\\nthe Desktop interactive app. This will open a desktop that\\xa0\\nis identical to the FastX one,\\xa0\\xa0 but instead of being on a login\\xa0\\nnode it will run on a compute node. This can be useful for users who\\xa0\\nwant to use GUI-based software. You can use the desktop app to run computationally\\xa0\\xa0 intensive work on a compute node rather\\xa0\\nthan using FastX on the login node. Additionally, if you have a large\\xa0\\namount of data to download from\\xa0\\xa0 cloud services like Google Drive,\\xa0\\nUVA Box, or Microsoft OneDrive,\\xa0\\xa0 you might find better performance on a\\xa0\\ncompute node rather than a login node. You can start these downloads and\\xa0\\nthen leave your computer for a bit. The downloads will continue even if you\\xa0\\nclose the browser or turn off your computer. The desktop app has this functionality because it\\xa0\\xa0 doesn't rely on your local internet\\xa0\\nconnection or the browser being open. This is a great way to run something on the\\xa0\\xa0 cluster in the background\\xa0\\nand come back to it later. Another available app is Matlab. Similar to RStudio, you will request what version\\xa0\\xa0 of Matlab you want to use\\xa0\\nwhen launching the session. Launching it will open the Matlab\\xa0\\ndesktop app within a desktop environment,\\xa0\\xa0 but closing the Matlab app will exit the session. If your files are not visible on the\\xa0\\ndesktop, you can access them from\\xa0\\xa0\",\n",
       "  \"the Places menu or the Caja app, which is the\\xa0\\nfiling cabinet icon at the top of the screen. Both Matlab and the desktop app persist if your\\xa0\\nnetwork is disconnected or if your browser closes. You can always relaunch those sessions to\\xa0\\nreconnect and your code will still be running. Finally, if you need help with UVA's HPC system,\\xa0\\nthere are multiple ways to get assistance. You can visit our Zoom-based office hours sessions\\xa0\\xa0 on Tuesdays from 3-5pm and\\xa0\\nThursdays from 10am to noon. If you can't make it to these office\\xa0\\nhours or have a more specific request,\\xa0\\xa0 you can submit a support ticket\\xa0\\nand we'll get back to you. Links to both are on the RC Learning website. The main Research Computing website\\xa0\\nis also a valuable resource. We add a lot of documentation\\xa0\\nhere and keep it updated. If you have a basic question or think it might\\xa0\\nbe covered already, we have an FAQ section. We also have a list of how to's on various topics. If you can't find what you're looking for,\\xa0\\xa0 we have a search feature where you can\\xa0\\nsearch our site for different information. This concludes the Open OnDemand Interactive\\xa0\\nApps tutorial at the University of Virginia. Thank you.\"],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'view_count': 23,\n",
       "   'length': 411,\n",
       "   'author': 'UVA Research Computing',\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM',\n",
       "   'start_timestamp': '00:00:00',\n",
       "   'publish_date': '2025-05-21',\n",
       "   'chunk_number': 1,\n",
       "   'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\",\n",
       "   'title': 'Connecting to HPC',\n",
       "   'source_type': 'youtube',\n",
       "   'start_seconds': 0,\n",
       "   'transcript_chunk_number': 1,\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'source': '94qLtfdsXaM'},\n",
       "  {'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'source_type': 'youtube',\n",
       "   'title': 'Connecting to HPC',\n",
       "   'start_timestamp': '00:02:00',\n",
       "   'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\",\n",
       "   'start_seconds': 120,\n",
       "   'chunk_number': 2,\n",
       "   'length': 411,\n",
       "   'transcript_chunk_number': 2,\n",
       "   'author': 'UVA Research Computing',\n",
       "   'source': '94qLtfdsXaM',\n",
       "   'view_count': 23,\n",
       "   'publish_date': '2025-05-21'},\n",
       "  {'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM',\n",
       "   'source': '94qLtfdsXaM',\n",
       "   'source_type': 'youtube',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'view_count': 23,\n",
       "   'start_timestamp': '00:04:00',\n",
       "   'chunk_number': 3,\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'publish_date': '2025-05-21',\n",
       "   'length': 411,\n",
       "   'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\",\n",
       "   'start_seconds': 240,\n",
       "   'title': 'Connecting to HPC',\n",
       "   'transcript_chunk_number': 3},\n",
       "  {'title': 'Connecting to HPC',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'publish_date': '2025-05-21',\n",
       "   'transcript_chunk_number': 4,\n",
       "   'length': 411,\n",
       "   'source': '94qLtfdsXaM',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'view_count': 23,\n",
       "   'start_seconds': 360,\n",
       "   'start_timestamp': '00:06:00',\n",
       "   'source_type': 'youtube',\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=94qLtfdsXaM',\n",
       "   'chunk_number': 4,\n",
       "   'description': \"This short tutorial provides an overview of methods to connect to the University of Virginia's HPC systems, including Open OnDemand, FastX, and SSH.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nFastX: https://fastx.hpc.virginia.edu/\\nUVA VPN: https://in.virginia.edu/vpn\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n0:39 Open OnDemand\\n2:09 FastX\\n4:20 SSH\\n5:51 VPN Info\\n6:02 Getting Help\"},\n",
       "  {'source': 'o9XVUhCQuEI',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'transcript_chunk_number': 1,\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help',\n",
       "   'view_count': 15,\n",
       "   'publish_date': '2025-06-15',\n",
       "   'start_seconds': 0,\n",
       "   'length': 658,\n",
       "   'chunk_number': 1,\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'source_type': 'youtube',\n",
       "   'start_timestamp': '00:00:00'},\n",
       "  {'transcript_chunk_number': 2,\n",
       "   'start_timestamp': '00:02:00',\n",
       "   'chunk_number': 2,\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help',\n",
       "   'length': 658,\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'view_count': 15,\n",
       "   'source': 'o9XVUhCQuEI',\n",
       "   'publish_date': '2025-06-15',\n",
       "   'start_seconds': 120,\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'source_type': 'youtube'},\n",
       "  {'view_count': 15,\n",
       "   'source_type': 'youtube',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'transcript_chunk_number': 3,\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'start_seconds': 240,\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help',\n",
       "   'publish_date': '2025-06-15',\n",
       "   'length': 658,\n",
       "   'start_timestamp': '00:04:00',\n",
       "   'chunk_number': 3,\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'source': 'o9XVUhCQuEI'},\n",
       "  {'source_type': 'youtube',\n",
       "   'start_timestamp': '00:06:00',\n",
       "   'publish_date': '2025-06-15',\n",
       "   'start_seconds': 360,\n",
       "   'length': 658,\n",
       "   'source': 'o9XVUhCQuEI',\n",
       "   'view_count': 15,\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'author': 'UVA Research Computing',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'chunk_number': 4,\n",
       "   'transcript_chunk_number': 4,\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help'},\n",
       "  {'start_timestamp': '00:08:00',\n",
       "   'view_count': 15,\n",
       "   'source': 'o9XVUhCQuEI',\n",
       "   'source_type': 'youtube',\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'transcript_chunk_number': 5,\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help',\n",
       "   'length': 658,\n",
       "   'author': 'UVA Research Computing',\n",
       "   'publish_date': '2025-06-15',\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'chunk_number': 5,\n",
       "   'start_seconds': 480},\n",
       "  {'start_timestamp': '00:10:00',\n",
       "   'title': 'Open OnDemand Interactive Apps',\n",
       "   'channel_id': 'UCDjikQvnYrZ3aNIdKgU54ag',\n",
       "   'transcript_chunk_number': 6,\n",
       "   'source': 'o9XVUhCQuEI',\n",
       "   'length': 658,\n",
       "   'view_count': 15,\n",
       "   'author': 'UVA Research Computing',\n",
       "   'start_seconds': 600,\n",
       "   'webpage_url': 'https://www.youtube.com/watch?v=o9XVUhCQuEI',\n",
       "   'source_type': 'youtube',\n",
       "   'description': 'This short tutorial provides an overview of the interactive apps available through Open OnDemand.\\n\\n*Important Links*\\nOpen OnDemand: https://ood.hpc.virginia.edu/\\nSlurm Partitions: https://learning.rc.virginia.edu/notes/slurm-from-cli/section1/#slurm-resource-requests\\nRC Learning: https://learning.rc.virginia.edu\\nMain RC Site: https://rc.virginia.edu\\n\\n*Video Chapters*\\n0:00 Intro\\n2:06 JupyterLab\\n8:08 RStudio\\n8:45 Desktop\\n9:38 MATLAB\\n10:10 Getting Help',\n",
       "   'publish_date': '2025-06-15',\n",
       "   'chunk_number': 6}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop langchain collection\n",
    "vector_store.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
